{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "InTFjGfIL5YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 1 - Managing Conversation History with Summarization\n"
      ],
      "metadata": {
        "id": "j6ZxygiCXx-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet openai"
      ],
      "metadata": {
        "id": "S7AAOrNIML8e"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"   # Groq API key\n",
        "os.environ[\"OPENAI_BASE_URL\"] = \"https://api.groq.com/openai/v1\"\n",
        "\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "_49bp_5pXl7Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Conversation Storage\n",
        "\n",
        "conversation_history = []\n",
        "run_counter = 0\n",
        "\n",
        "def add_message(role, content):\n",
        "    \"\"\"Add user/assistant/system message to history\"\"\"\n",
        "    conversation_history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "def print_history():\n",
        "    \"\"\"Print conversation history\"\"\"\n",
        "    print(\"\\n--- Conversation History ---\")\n",
        "    for m in conversation_history:\n",
        "        print(f\"{m['role']}: {m['content']}\")"
      ],
      "metadata": {
        "id": "0jOQGH4HXl94"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Summarization Function\n",
        "\n",
        "def summarize_history(history):\n",
        "    \"\"\"Summarize entire conversation so far using Groq API\"\"\"\n",
        "    messages = [{\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in history]\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"moonshotai/kimi-k2-instruct-0905\",   # Used Moonshotai model (Groq-supported model)\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Summarize the following conversation concisely.\"},\n",
        "            *messages\n",
        "        ],\n",
        "        max_tokens=100\n",
        "    )\n",
        "    return completion.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "uSKzh24BXmAY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Truncation Options\n",
        "\n",
        "def truncate_by_turns(n):\n",
        "    \"\"\"Keep only the last n conversation turns\"\"\"\n",
        "    global conversation_history\n",
        "    conversation_history = conversation_history[-n:]\n",
        "\n",
        "def truncate_by_length(max_chars):\n",
        "    \"\"\"Keep only messages within max character length\"\"\"\n",
        "    global conversation_history\n",
        "    result, total_len = [], 0\n",
        "    for m in reversed(conversation_history):\n",
        "        if total_len + len(m[\"content\"]) <= max_chars:\n",
        "            result.insert(0, m)\n",
        "            total_len += len(m[\"content\"])\n",
        "        else:\n",
        "            break\n",
        "    conversation_history = result"
      ],
      "metadata": {
        "id": "RDvIimpiXmC-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Periodic Summarization\n",
        "\n",
        "def on_new_run(role, content, k=3):\n",
        "    \"\"\"\n",
        "    Add message, increment run counter,\n",
        "    summarize every k-th run, replace history with summary + last message\n",
        "    \"\"\"\n",
        "    global run_counter, conversation_history\n",
        "\n",
        "    add_message(role, content)\n",
        "    run_counter += 1\n",
        "\n",
        "    if run_counter % k == 0:\n",
        "        print(\"\\n[Summarizing conversation...]\")\n",
        "        summary = summarize_history(conversation_history)\n",
        "        conversation_history = [{\"role\": \"system\", \"content\": f\"SUMMARY -> {summary}\"}]\n",
        "        conversation_history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "    print_history()"
      ],
      "metadata": {
        "id": "388lTtenXmFY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Demonstration\n",
        "\n",
        "print(\"=== Demo: Conversation Flow ===\")\n",
        "\n",
        "\n",
        "on_new_run(\"user\", \"Hi, I'm Rahul. Can you help me with my project?\")\n",
        "on_new_run(\"assistant\", \"Of course, Rahul. What is the project about?\")\n",
        "on_new_run(\"user\", \"It's about conversation summarization using Groq API.\")  # triggers summarization at 3rd run\n",
        "on_new_run(\"assistant\", \"Got it. We need to store history and make summaries.\")\n",
        "on_new_run(\"user\", \"Yes, also truncate messages when it gets too long.\")\n",
        "\n",
        "print(\"\\n=== Demo: Truncation by last 2 turns ===\")\n",
        "truncate_by_turns(2)\n",
        "print_history()\n",
        "\n",
        "print(\"\\n=== Demo: Truncation by 50 characters ===\")\n",
        "truncate_by_length(50)\n",
        "print_history()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcGo0-o4XmHt",
        "outputId": "90a426e8-3e48-41f8-aa2a-3ee587458020"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Demo: Conversation Flow ===\n",
            "\n",
            "--- Conversation History ---\n",
            "user: Hi, I'm Rahul. Can you help me with my project?\n",
            "\n",
            "--- Conversation History ---\n",
            "user: Hi, I'm Rahul. Can you help me with my project?\n",
            "assistant: Of course, Rahul. What is the project about?\n",
            "\n",
            "[Summarizing conversation...]\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Got it—you're building a conversation-summarizer that calls Groq's API. How far along are you, and where are you stuck?\n",
            "user: It's about conversation summarization using Groq API.\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Got it—you're building a conversation-summarizer that calls Groq's API. How far along are you, and where are you stuck?\n",
            "user: It's about conversation summarization using Groq API.\n",
            "assistant: Got it. We need to store history and make summaries.\n",
            "\n",
            "--- Conversation History ---\n",
            "system: SUMMARY -> Got it—you're building a conversation-summarizer that calls Groq's API. How far along are you, and where are you stuck?\n",
            "user: It's about conversation summarization using Groq API.\n",
            "assistant: Got it. We need to store history and make summaries.\n",
            "user: Yes, also truncate messages when it gets too long.\n",
            "\n",
            "=== Demo: Truncation by last 2 turns ===\n",
            "\n",
            "--- Conversation History ---\n",
            "assistant: Got it. We need to store history and make summaries.\n",
            "user: Yes, also truncate messages when it gets too long.\n",
            "\n",
            "=== Demo: Truncation by 50 characters ===\n",
            "\n",
            "--- Conversation History ---\n",
            "user: Yes, also truncate messages when it gets too long.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ym32wQPXY7XL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 2 : JSON Schema Classification & Information Extraction"
      ],
      "metadata": {
        "id": "RcapLyI7Yvt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os, json\n",
        "from jsonschema import validate, ValidationError\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"   # Groq API key\n",
        "os.environ[\"OPENAI_BASE_URL\"] = \"https://api.groq.com/openai/v1\"\n",
        "\n",
        "client = OpenAI()\n"
      ],
      "metadata": {
        "id": "WfM1jEaSa9OI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON Schema for extracting details\n",
        "\n",
        "user_info_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"email\": {\"type\": \"string\"},\n",
        "        \"phone\": {\"type\": \"string\"},\n",
        "        \"location\": {\"type\": \"string\"},\n",
        "        \"age\": {\"type\": \"integer\"}\n",
        "    },\n",
        "    \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "}\n"
      ],
      "metadata": {
        "id": "IkyALg76WyZA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_user_info(conversation_text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"moonshotai/kimi-k2-instruct-0905\",   # Groq supported model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Extract user details into structured JSON.\"},\n",
        "            {\"role\": \"user\", \"content\": conversation_text}\n",
        "        ],\n",
        "        functions=[\n",
        "            {\n",
        "                \"name\": \"extract_user_info\",\n",
        "                \"description\": \"Extracts personal details from conversation\",\n",
        "                \"parameters\": user_info_schema\n",
        "            }\n",
        "        ],\n",
        "        function_call={\"name\": \"extract_user_info\"}\n",
        "    )\n",
        "\n",
        "    args = response.choices[0].message.function_call.arguments\n",
        "    return json.loads(args)\n"
      ],
      "metadata": {
        "id": "w-Lt3V9KbKsj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_extracted(data):\n",
        "    try:\n",
        "        validate(instance=data, schema=user_info_schema)\n",
        "        return True, None\n",
        "    except ValidationError as e:\n",
        "        return False, str(e)\n"
      ],
      "metadata": {
        "id": "BN5xwE6wbNYH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_chats = [\n",
        "    \"Hi, I’m Rahul Sharma. My email is rahul@example.com, phone number is 9876543210, I live in Bangalore, and I’m 25 years old.\",\n",
        "    \"Hello, this is Ananya Singh, I’m 30. You can reach me at ananya@gmail.com or call me on 9123456789. I stay in Mumbai.\",\n",
        "    \"Hey! My name is Arjun Mehta, I’m 22 years old. Email: arjunm22@yahoo.com, phone: 9988776655, and I’m from Delhi.\"\n",
        "]\n",
        "\n",
        "for i, chat in enumerate(sample_chats, 1):\n",
        "    print(f\"\\n=== Sample Chat {i} ===\")\n",
        "    extracted = extract_user_info(chat)\n",
        "    is_valid, error = validate_extracted(extracted)\n",
        "\n",
        "    print(\"Extracted JSON:\", extracted)\n",
        "    print(\"Validation:\", \"PASS ✅\" if is_valid else f\"FAIL ❌ - {error}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGN8x7bwbNbt",
        "outputId": "09286f8c-0c03-4c0a-c8e9-722f29748482"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sample Chat 1 ===\n",
            "Extracted JSON: {'age': 25, 'email': 'rahul@example.com', 'location': 'Bangalore', 'name': 'Rahul Sharma', 'phone': '9876543210'}\n",
            "Validation: PASS ✅\n",
            "\n",
            "=== Sample Chat 2 ===\n",
            "Extracted JSON: {'age': 30, 'email': 'ananya@gmail.com', 'location': 'Mumbai', 'name': 'Ananya Singh', 'phone': '9123456789'}\n",
            "Validation: PASS ✅\n",
            "\n",
            "=== Sample Chat 3 ===\n",
            "Extracted JSON: {'age': 22, 'email': 'arjunm22@yahoo.com', 'location': 'Delhi', 'name': 'Arjun Mehta', 'phone': '9988776655'}\n",
            "Validation: PASS ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DXfrVYaEbd3D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}